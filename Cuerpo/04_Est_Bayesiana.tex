\chapter{La probabilidad no existe}
	
	Cuando nos enfrentamos a situaciones inciertas, constantemente medimos nuestra incertidumbre de manera personal, con base en la información que tenemos disponible. Esta medición la expresamos coloquialmente mediante el término \textit{probabilidad}. Por ejemplo, nos podemos preguntar la probabilidad de que en una elección popular, una candidatura haya recibido entre el 30\% y el 35\% de los votos. Más aún, como dice \textcite[75]{Berger85}, es común ``pensar en términos de probabilidades personales todo el tiempo: cuando se apuesta al resultado de un partido de fútbol americano, cuando se evalúa la posibilidad de lluvia al día siguiente...''. Es decir, día con día utilizamos el término probabilidad para referirnos a apreciaciones subjetivas de la plausibilidad de cosas inciertas. A esta conceptualización de la probabilidad como una medida personal de la incertidumbre se le conoce como el paradigma subjetivo o \textit{bayesiano}. Esta es una interpretación filosófica radicalmente distinta a las más tradicionales: la empírica o \textit{frecuentista} y la \textit{clásica} \parencites[19,27]{Nozer17}[16]{GP16}. 
	
\section{¿Probabilidad o probabilidades?}

	Desde la óptica bayesiana, la probabilidad en sentido matemático no sería, pues, un concepto ajeno ni incompatible al cotidiano; por el contrario, siendo en el fondo el mismo, permitiría extender su uso a todas aquellas situaciones en las que no aplican las otras perspectivas \parencite{Berger85,GP16}. ¿Cuáles serían algunos ejemplos de dichas situaciones?\\
	
	El paradigma clásico está basado ``en ciertas \textit{simetrías} o en propiedades físicas''\parencite[19; itálicas en el original]{GP16}. En virtud de dichas simetrías las probabilidades asignadas a los eventos son iguales. Por ello, puede aplicarse a situaciones proclives al consenso, generalmente juegos de azar, y donde la regla general de probabilidades es: casos favorables entre casos totales. En lo que respecta a las probabilidades personales, éstas pueden o no coincidir, incluso en las situaciones más proclives a un consenso. Un lanzamiento de una moneda tiene dos posibles resultados igualmente probables... o no. Reducir la probabilidad a que \textit{siempre} deba ser 0.5 es un error \parencite[28]{Nozer17}. Si alguien tiene pruebas de que una moneda particular está cargada, pudiera asignar una probabilidad radicalmente distinta al águila que al sol, mientras que quien desconoce esta información medirá la incertidumbre que rodea al lanzamiento con una asignación equiprobable. Ambas mediciones son válidas, solamente difieren en que son realizadas por sujetos con distinto grado de incertidumbre o conocimiento sobre el fenómeno de interés. Lo que sí podemos decir es que esta interpretación clásica es la más restrictiva pues se reduce al hecho de que la probabilidad de algún evento siempre es equitativa y los casos en los que eso sea una buena aproximación a la realidad son relativamente pocos.\\	 
	 
	Por otro lado, para el paradigma frecuentista, la probabilidad es un límite de frecuencias relativas de eventos repetidos bajo condiciones similares. Es una extensión del concepto clásico: casos favorables entre casos totales, cuando los casos totales tienden a infinito. Así, ``únicamente los sucesos que pueden ser repetidos tienen probabilidad''\parencite[4]{Aquino10}. Es decir, la probabilidad sería una propiedad de un colectivo  y no de eventos individuales \parencite[17]{Nozer17}. ¿Cuál sería pues la probabilidad de que cierto partido político gane las próximas elecciones presidenciales en México o de que la Selección Nacional logre jugar un quinto partido en el siguiente Mundial de futbol? Dichos eventos son únicos, no pueden repetirse infinitamente bajo las mismas circunstancias con tal de que seamos capaces de registrar empíricamente su límite de frecuencias relativas. Claro, podemos pensar en que hayan \textit{suficientes} eventos bajo condiciones \textit{similares} como para que la probabilidad sea aproximadamente, digamos, 30\%. Pero, ¿cuántos eventos son suficientes? y ¿qué tan similares deben ser? \parencite[23-24]{Nozer17}. Por el contrario, para la perspectiva bayesiana sí que podemos expresar, cada uno de nosotros, nuestras probabilidades subjetivas sobre ellos.\\ 
	
	De manera general se podría decir que los paradigmas tradicionales interpretan la probabilidad exclusivamente como una medida de variabilidad. Dicha variabilidad es un concepto necesario, ciertamente, pero más limitado que aquél de incertidumbre: la incertidumbre puede derivarse de la variabilidad, pero existen muchos fenómenos invariantes que son inciertos. Pensemos en el ejemplo al que me refería al inicio de este capítulo. La proporción de votos de una candidatura en una elección es una proporción fija y que no varía--- al cierre de la votación, al menos---. Sin embargo, nos podemos hacer preguntas probabilísticas acerca de ella porque, hasta que no se anuncian los resultados oficiales, ésta es desconocida. Incluso es posible llevar este argumento al extremo: ¿cuál es la probabilidad de que mis dos hermanos cumplan años el mismo día? Este es un evento cierto o falso, totalmente determinado en el pasado pues, o bien nacieron el mismo día del año o no. Por lo mismo, en estricto sentido sería difícil hacer una estimación probabilística de ello desde el punto de vista lógico o frecuentista. Alguien podría intentar hacer el argumento de que, asumiendo equiprobabilidad e ignorando los años bisiestos, esta debería ser de una en 365. Alguien más, en un espíritu más frecuentista, podría decir que ésta debe ser la probabilidad de que sean gemelos y, por lo mismo, igual a la proporción de nacimientos gemelares. Si me preguntan a mí, les diría que esa probabilidad es 1: sé que ambos nacieron el 16 de diciembre.\\	
	
	El estadístico y actuario italoaustríaco Bruno de Finetti, acuñó la frase que le da nombre a este capítulo y que sintetiza esta visión bayesiana de la probabilidad. Para los bayesianos, LA probabilidad única, absoluta y objetiva no existe; más bien es una medida subjetiva de la incertidumbre que un individuo particular tiene frente al fenómeno de interés.\\ 
	
	
	Esta argumentación filosófica se ve reforzada por una justificación matemática formal: la teoría de decisión bayesiana. Con base en unos axiomas, llamados de coherencia , se puede demostrar que un decisor, ante un problema de decisión con incertidumbre, debe actuar de la siguiente manera:\footnote{En el sentido normativo de que esta es la manera óptima de actuar si se quiere evitar violar los axiomas de coherencia y de ninguna manera en un sentido descriptivo que diga que los seres humanos actuamos de dicha forma o incluso, llevando el argumento al extremo, que se tengan que aceptar dichos axiomas.} 

\begin{enumerate}
\item Expresar su incertidumbre sobre los eventos inciertos relevantes en una medida llamada probabilidad (subjetiva).
\item Reflejar sus preferencias sobre las posibles consecuencias mediante otra medida llamada utilidad). 
\item Tomar la decisión que maximice la utilidad esperada o, equivalentemente, minimice la pérdida esperada. 
\end{enumerate}   
	
Dicha justificación axiomática escapa mis objetivos pero una primera introducción a ella puede consultarse en referencias como \textcite{Mendoza11} o \textcite{Bernardo81}.\\

Por otro lado, este procedimiento bayesiano está encaminado, de cierta forma, a reducir el riesgo de las consecuencias que puedan surgir en un problema de decisión. Cualquier decisor que \textit{usa} la teoría bayesiana hará esto. Sin embargo, desde mi punto de vista, la diferencia entre ello y lo que hace un decisor bayesiano estriba en que éste último se preocupa también por minimizar la incertidumbre asociada al fenómeno de su interés. ¿Cómo podemos realizar un análisis dentro de la teoría de la decisión que busque reducir la incertidumbre? Recabando mayor información. En el contexto de la estadística esto significa obtener datos. Frecuentemente, en mi trabajo, bromeamos sobre el bayesiano que no necesita datos para estimar lo que sea, pues bastan sus probabilidades y pérdidas subjetivas. Sin embargo, al margen del buen humor, la realidad es que si solo tomamos decisiones \textit{a priori} estamos siendo obtusos. En el mejor de los casos, diremos que ya contamos con la única información disponible; en el peor, estaríamos siendo víctimas de una ciega soberbia. Por lo mismo, el \textit{estadístico bayesiano} debe primero preocuparse por los datos y, una vez recabados, proceder al análisis. Así pues, es necesario continuar esta breve introducción al paradigma bayesiano presentando el mecanismo por el cual un estadístico bayesiano aprende de los datos y actualiza sus creencias subjetivas.\\
	
\section{Aprendizaje bayesiano}

Un punto clave de la teoría de decisión bayesiana es que la definición matemática de la probabilidad subjetiva satisface los axiomas de Kolmogorov que dan sustento a la teoría usual de probabilidades. Es decir, las probabilidades subjetivas satisfacen los mismos teoremas y resultados que se aprenden en los cursos de probabilidad. Uno de los más elementales es el teorema que hace posible este \textit{aprendizaje bayesiano} de los datos: el Teorema de Bayes.

\begin{teo} \label{teo:Bayes_1}
\textbf{Teorema de Bayes. (Versión probabilística)}\\
Sean $A$ y $B$ eventos tales que $P(B) \neq 0$. Se cumple que: 
\begin{equation*}
P(A|B)=\dfrac{P(B|A)P(A)}{P(B)}\;,
\end{equation*}
donde $P(A|B)$ y $P(B|A)$ son probabilidades condicionales, mientras que $P(A)$ y $P(B)$ son las respectivas probabilidades marginales. 
\end{teo}

Vale la pena detenerse a pensar qué implica este teorema en el contexto de la estadística bayesiana; no por nada el apelativo de nuestro paradigma es justamente \textit{bayesiano}, en honor a Thomas Bayes, mismo personaje al que se refiere el teorema. Cuando hacemos inferencia estadística (paramétrica), usualmente estamos interesados en conocer sobre una cantidad desconocida $\theta$, llamada parámetro. Bajo el paradigma bayesiano, éste es tratado como si fuera una variable aleatoria y, por tanto, le asignamos una  distribución de probabilidad \textit{inicial} o \textit{a priori} $p(\theta)$. Esta $p(\theta)$ resume nuestro estado de conocimiento inicial sobre el parámetro.\footnote{El caracter subjetivo de las probabilidades implica que cada una es condicional al conocimiento particular del decisor. Esto se puede representar como unas condiciones $H$, por lo que formalmente debería escribirse $p(\theta|H)$. Sin embargo, para no hacer demasiado complicada la notación, usualmente no se hace explícita dicha condición. Por ese motivo, un bayesiano dirá que todas las probabilidades son condicionales y que las probabilidades puramente marginales no existen.} Posteriormente, para reducir nuestra incertidumbre procedemos a recabar información en forma de datos $x$. Finalmente determinamos una distribución sobre dichos datos dado el parámetro--- $p(x|\theta)$--- y que, como función del parámetro, es llamada función de verosimilitud--- $L(\theta)$---. Nuestro objetivo entonces es \textit{invertir} las probabilidades y conocer la distribución del parámetro dado los datos $p(\theta|x)$.\footnote{Precisamente una de las primeras motivaciones de la estadística bayesiana era justamente la de encontrar una forma de calcular estas \textit{probabilidades inversas} \citep[8]{Robert07}.} Esto lo hacemos mediante el teorema de Bayes: 

\begin{teo} \label{teo:Bayes_2}
\textbf{Teorema de Bayes. (Versión estadística)}\\
Sean $\theta$ un vector de parámetros desconocidos, $p(\theta)$ su distribución inicial y $x$ información adicional en forma de datos conocidos. Entonces, la distribución posterior de $\theta$, una vez observados los datos, es: 
\begin{equation*}
p(\theta|x)=\dfrac{p(x|\theta)p(\theta)}{p(x)}\;,
\end{equation*}
donde $p(x|\theta) = L(\theta)$ es la función de verosimilitud de los datos $x$ dado el vector de parámetros $\theta$ y con $p(x)$ la distribución marginal de los datos. 
\end{teo}

Visto todo como función de $\theta$, nuestra cantidad de interés, la expresión anterior se reduce a:  
\begin{equation} \label{equation:Bayes_Prop}
p(\theta|x) \propto L(\theta)p(\theta)\;,
\end{equation}
pues $p(x)$ depende solo de los datos ya observados y funge como la constante normalizadora que hace que la posterior integre a 1. Esta última representación resume el proceso de aprendizaje bayesiano: \textit{la posterior es proporcional a la verosimilitud por la inicial}.\footnote{Una observación adicional es que, si obtenemos otros datos independientes de los primeros, podemos aplicar el teorema de manera secuencial--- pues la distribución posterior con los primeros datos se convierte en la inicial para los segundos --- o bien todo de una vez \parencites[37-39]{Lee12}[35-36]{GP16}[23]{Robert07}.} Así pues, gracias al teorema de Bayes podemos actualizar nuestras creencias inciales, aprendiendo de los datos, para posteriormente tomar una decisión. ¿Qué tipo de decisiones tomamos cuando hacemos inferencia estadística bayesiana? Esa es la conexión entre la teoría de decisión y la estadística y de eso hablo en la siguiente sección. 

\section{La única receta de la inferencia bayesiana}

En muchas ocasiones, se debe tomar una decisión y para ayudar a tomarla se utiliza la estadística. Como dicen \textcite[237]{Gelman13} o \textcite[1]{Robert07}, muchos, si no es que la mayoría, de los análisis estadísticos se realizan con el objetivo final de tomar una decisión. Ellos mismos, así como \textcite{Berger85}, presentan varios ejemplos al respecto. Empero, el propio proceso de inferencia estadística puede plantearse como un problema de decisión. Por ello, discuto brevemente algunos problemas usuales de la inferencia estadística desde esta óptica y termino la sección con una ``receta'' que resume el proceso de inferencia bayesiana.

\subsection{Problemas de inferencia bayesiana}

Normalmente son tres los procedimientos de inferencia estadística más mencionados: contraste o prueba de hipótesis, estimación puntual y estimación por intervalos. Como mencionan \textcite[58-59]{Mendoza11} y \textcite[7]{Robert07}, también debemos considerar el problema de predicción como uno fundamental en la inferencia estadística. 

\subsubsection*{Prueba de hipótesis}

El procedimiento de inferencia estadística más sencillo de interpretar como problema de decisión es la prueba de hipótesis. Supongamos que tenemos una hipótesis nula $H_0$ y una alternativa $H_1$. Digamos que $H_0:\,\theta \,\in\,\Theta_0$ y $H_1:\,\theta \,\in\,\Theta_1$, donde $\Theta_0$ y $\Theta_1$ son dos subconjuntos del espacion parametral $\Theta$. Las decisiones que podemos tomar serían aceptar a $H_0$ o a $H_1$ como la hipótesis más cercana a la realidad. ¿Cuál hipótesis debemos elegir? El procedimiento es minimizar la pérdida esperada. Para ello definimos nuestra distribución inicial, nuestra función de pérdida y recabamos una muestra aleatoria $x$. Usualmente se asume que equivocarse conlleva una pérdida de valor $1$ pero no equivocarse no conlleva ninguna.\footnote{Esta función de pérdida es conocida como pérdida 1-0.} Bajo estas condiciones debemos rechazar $H_0$ y elegir $H_1$ cuando la probabilidad posterior de que el verdadero valor del parámetro esté en $\Theta_1$ sea mayor a la probabilidad posterior de que se encuentre en $\Theta_0$ \parencite[49-52]{Mendoza11}. Es decir, en términos más sencillos, deberíamos elegir la hipótesis más probable una vez que observamos los datos.\\ 

Lo elegante de esta solución contrasta con lo poco claro que puede resultar el procedimiento tradicional. Bajo este paradigma bayesiano, estamos preguntándonos por las \textit{probabilidades de las hipótesis, dados los datos}. Esta es una aproximación más intuitiva que el enfoque frecuentista que mide probabilidades en el espacio de los datos, como el valor p que indica la probabilidad \textit{si la hipótesis nula fuese verdadera} de observar datos al menos tan extremos como los observados realmente \parencite[2; énfasis mío.]{Congdon06}. Normalmente pensaríamos que rechazar una hipótesis nula al 5\%, significaría que hay una probabilidad de que sea verdadera de tan solo el 5\% y, sin embargo, los libros constantemente advierten que éste no es el caso. Esta es una confusión que se evita desde el enfoque bayesiano, como bien dice \textcite[xxi]{Lee12}. 

\subsubsection*{Estimación puntual}

Otra herramienta básica de la inferencia es la estimación puntual en la que queremos estimar un parámetro $\theta$ con un estimador $\hat{\theta}$. En este caso, las posibles decisiones son los valores del estimador que podríamos adoptar. Existe una multiplicidad de opciones comúnmente aceptadas como pérdida \parencite{Berger85,Mendoza11,Nieto16}. Una forma de razonar es que, entre más alejado del verdadero valor $\theta$ se encuentre nuestro estimador $\hat{\theta}$, mayor deberá ser la pérdida \parencite[53]{Mendoza11}. Así, una muy utilizada es la llamada cuadrática: $L(\hat{\theta},\theta)=(\theta-\hat{\theta})^2$. El estimador puntual óptimo bajo pérdida cuadrática resulta ser la media posterior. Si se eligen otras pérdidas, podemos estimar con la mediana o, incluso, con la moda.\footnote{Esto se menciona en \textcite{Berger85}, \textcite{Nieto16} y se demuestran los resultados en \textcite[39-43]{Usi14} o en \textcite[234-240]{Lee12}. Quizás la primera referencia que habla de un estimador derivado de esta forma es de Laplace en 1773, cuando refiere que la mediana posterior minimiza el error absoluto esperado \parencite[12, Ejemplo 1.2.5]{Robert07}; es decir, bajo pérdida absoluta $L(\hat{\theta},\theta)=|\theta-\hat{\theta}|$, la mediana de la distribución posterior es la decisión óptima.}

\subsubsection*{Estimación por intervalos}

Otro de los procedimientos frecuentistas con una interpretación rebuscada es el de intervalo de confianza. Cuando construimos un intervalo al 95\% sabemos que, de repetir el mismo procedimiento con diferentes muestras una cantidad suficiente de veces, aproximadamente el 95\% de las veces los intervalos resultantes contendrán al verdadero parámetro. El intervalo específico, con los datos observados, puede o no ser de ese 95\% \parencite[p. 2]{Congdon06}. Por el contrario, cuando reportamos un intervalo de probabilidad bayesiano del 95\%, efectivamente estamos diciendo que el verdadero valor del parámetro $\theta$ se encuentra dentro del mismo con una probabilidad de 0.95. Al parecer, las recetas frecuentistas--- parafraseando a \textcite[p. xxi]{Lee12}--- no responden las preguntas que uno se hace naturalmente sino que más bien responden preguntas complicadas que pocos realmente se harían. El paradigma bayesiano, en este sentido, tiene una interpretación mucho más intuitiva. Para ver un planteamiento de este problema de inferencia estadística como problema de decisión se puede consultar \textcite[pp. 56-58]{Mendoza11}. 

\subsubsection*{Predicción}

Cuando se conoce el valor del parámetro $\theta$, resulta natural intentar predecir el resultado de una observación futura $\tilde{x}$ mediante la distribución condicional $p(\tilde{x}|\theta)$. Sin embargo, en el contexto de incertidumbre sobre los parámetros en el que estamos trabajando debemos considerar también que el valor específico de $\theta$ es desconocido. Así pues, debemos considerar más bien la distribución conjunta de las dos cantidades desconocidas, $\tilde{x}$ y $\theta$. A partir de esta distribución $p(\tilde{x},\theta)$ podemos obtener la distribución marginal de la observación futura y con ella predecir: 
\begin{equation*} 
p(\tilde{x})=\int\limits_\Theta p(\tilde{x},\theta)d\theta=\int\limits_\Theta p(\tilde{x}|\theta)p(\theta)d\theta.
\end{equation*}
Esta distribución marginal es conocida como \textit{distribución predictiva inicial}. Al calcularla estamos promediando las distribuciones condicionales a través de los diferentes valores que el parámetro $\theta$ puede tomar. Sin embargo, como ya he mencionado con anterioridad, nuestro interés principal es tomar decisiones--- en este caso predecir--- reduciendo la incertidumbre a través de datos. Buscaremos tener entonces una \textit{distribución predictiva posterior} que tome en cuenta la información proporcionada por los datos observados. Bajo el esquema paramétrico, la observación futura sería condicionalmente independiente de los datos, dado el verdadero valor del parámetro. Así pues, condicionando sobre el parámetro e integrando debido a que realmente no conocemos su verdadero valor, tenemos lo siguiente:
\begin{align*}
p(\tilde{x}|x)&=\int\limits_\Theta p(\tilde{x},\theta|x)d\theta \\
&=\int\limits_\Theta p(\tilde{x}|\theta,x)p(\theta|x)d\theta\\
&=\int\limits_\Theta p(\tilde{x}|\theta)p(\theta|x)d\theta\;.
\end{align*}
En este punto, procedemos de manera análoga al caso de estimación puntual o por intervalos, dependiendo del tipo de predicción que queramos hacer.

\subsection{La receta}

He hablado de los principales problemas de inferencia estadística como problemas de decisión. También he hecho énfasis en la importancia de tomar dichas decisiones una vez observados los datos con el fin de reducir tanto el riesgo como la incertidumbre. Independientemente de la pérdida particular que el estadístico tenga, el otro componente fundamental con el que tomaría la decisión es con la distribución posterior. Esto motiva lo que \textcite[p.29]{GP16} llama la \textit{única receta de la inferencia bayesiana}: 
\begin{quote}
... encontrar la distribución condicional de todas aquellas cantidades de interés cuyo valor desconocemos dado el valor conocido de las variables observadas.
\end{quote}
Puesto de otra forma por el mismo autor: la distribución final es la inferencia. Ahora bien, llamarla única receta es un recurso mnemotécnico, pues como bien advierte el autor, así como \textcite{Berger85}, es deseable resumir esta inferencia general en un proceso específico. Christian P. \textcite[8-9]{Robert07} también hace énfasis en la importancia de hacer inferencia estadística basados en la distribución posterior. Como bien dice, 
\begin{quote}
... el propósito de un análisis estadístico es fundamentalmente un propósito de \textit{inversión}, puesto que busca recuperar las causas--- reducidas a los parámetros del mecanismo probabilístico de generación--- de los efectos--- resumidos por las observaciones. En otras palabras, al observar un fenómeno aleatorio dirigido por un parámetro $\theta$, los métodos estadísticos permiten deducir de estas observaciones una \textit{inferencia} (esto es, un resumen, una caracterización) sobre $\theta$ [...] La inferencia está basada entonces en la distribución de $\theta$ condicional en $x$ [...] llamada la \textit{distribución posterior}...\footnote{Itálicas en el original, traducción propia.}
\end{quote}

\section{Distribuciones iniciales}

En las secciones anteriores he tratado de exponer y enfatizar que un análisis bayesiano debería tener como objetivo práctico aprender de los datos, invirtiendo probabilidades, para calcular \textit{distribuciones posteriores}. Sin embargo, para lograr esto es necesario empezar con una \textit{distribución inicial} que, como he mencionado, refleje la incertidumbre que se tenga frente a un fenómeno de interés. Existen muchas formas diferentes de determinar la distribución inicial, en esta sección presentaré algunas de ellas con base en \textcites[Cap. 3]{Berger85}[Cap. 1]{Congdon06}[Caps. 2-3]{Robert07}[Caps. 1-2]{Gelman13}.\\ 

Empecemos por considerar el caso cuando el espacio parametral sobre el que tenemos que determinar las probabilidades es discreto. Por ejemplo, pensemos en fijar una distribución inicial para un partido de futbol, en el que hay 3 posibles resultados: victoria para el local, victoria para el visitante o empate. La primera distribución posible está basada en lo que se conoce como el \textit{criterio de la razón insuficiente}. Fue propuesto por Laplace y está relacionado a la interpretación clásica de la probabilidad puesto que establece que, a falta de información adicional que permita invalidarlo, se debería tomar el supuesto de que todos los eventos son igualmente probables. Así pues, podríamos asignar una distribución discreta uniforme de $1/3$ a cada uno de los 3 resultados del partido.\\

Sin embargo, podría haber razones suficientes para que esta no sea la distribución inicial. Por ejemplo, podemos creer que el equipo local es mejor que el equipo visitante. Y asignar una probabilidad del  60\% a que el local gane. Quedaría repartir el 40\% restante entre el empate y una sorpresiva victoria del visitante. Podríamos pensar que es 3 veces más probable un empate que una victoria del visitante, por lo que repartiríamos el 40\% como 30\% y 10\%. Otro aficionado, quizás piensa que un 30\% de probabilidad de empate es demasiado alto, en cuyo caso sería necesario ajustar las probabilidades así calculadas hasta encontrar una combinación aceptable. Pudiéramos también asignar una distribución inicial basados en algún tipo de frecuencia relativa histórica.\\ 

Otra forma de asignar probabilidades a eventos es pensar en apuestas que consideremos justas. Imaginemos un mercado como el del sitio web 	https://www.predictit.org/ en el que podemos apostar una cantidad $p \in (0,1)$ de centavos de dólar a que un evento suceda. Si el evento efectivamente sucede, nuestra apuesta vale $1$ dólar y habremos ganado $1-p$ centavos. Si el evento no sucede, perdemos $p$ centavos. Por otro lado, pensemos en una apuesta justa, es decir, una cuya ganacia esperada fuera $0$. La ganancia esperada $E[g]$ es igual a la ganancia cuando el evento sucede, por la probabilidad de que suceda, más la ganancia--- en este caso, negativa--- cuando el evento no sucede, por la probabilidad de que no suceda. Si denotamos al evento como $E$ y a su probabilidad como $P(E)$, tenemos que : 
\begin{align*}
E[g] = 0 &\Leftrightarrow (1-p)P(E) - pP(E^c) = 0 \\
&\Leftrightarrow (1-p)P(E) - p(1-P(E))= 0\\ 
&\Leftrightarrow P(E) - p = 0\\
&\Leftrightarrow P(E) = p.
\end{align*}
Si apostáramos una cantidad mayor estaríamos arriesgándonos de más, o dicho de otra forma, tendríamos una ganancia esperada negativa, por lo que no nos convendría la apuesta. Querríamos apostar menos, pues en ese caso nuestra ganancia esperada sería positiva. Esto quiere decir que podemos pensar en las probabilidades subjetivas de un evento como la máxima cantidad que estaríamos dispuestos a considerar en una apuesta de este tipo.\footnote{Sabemos que cuando se trata de apuestas, la gente tiende a ser aversa al riesgo, lo que haría que alguien nos dijera que la ganancia esperada tendría que ser muy positiva para siquiera considerar una apuesta. De manera análoga, alguien amante al riesgo podría estar dispuesto a apostar aún con una ganancia esperada negativa. Sin embargo, consideremos que la apuesta es meramente imaginativa como mecanismo para dilucidar probabilidades subjetivas y que las cantidades apostadas serían en teoría lo suficientemente pequeñas como para pensar en una utilidad lineal del dinero.}\\

Más frecuentemente, sin embargo, la distribución inicial debe ser continua. ¿Cómo elegirla? A continuación presento algunos métodos.  

\subsection{Distribuciones iniciales no informativas}

Al igual que con las distribuciones discretas podemos comenzar por el criterio de la razón insuficiente y proponer una distribución que busque reflejar una ignorancia general en la que no se prefieran \textit{a priori} algunos resultados o valores de los parámetros. Así surgen las llamadas \textit{distribuciones iniciales no informativas}. Éstas se usan, generalmente, por dos motivos. En primer lugar, podemos creer que no contamos con información inicial y que, efectivamente, nuestra ignorancia es total. Alternativamente, podemos ignorar la información existente porque queremos presentar una distribución relativamente más objetiva, ya sea porque el contexto así lo exige, porque se busca llevar acabo un análisis de sensibilidad bajo diferentes supuestos o por algún otro motivo.\\ 

El criterio de la razón insuficiente lleva a proponer una asignación equiprobable a los eventos. Así pues, la primera distribución inicial no informativa que se puede considerar es la uniforme. Esto es que la distribución sea proporcional a una constante:
\begin{equation*}
p(\theta) \propto c
\end{equation*}
Esta distribución, sin embargo, ha sufrido algunas críticas. La primera de ellas es que, si uno quiere reflejar incertidumbre total sobre un parámetro, esto querría decir que también deberíamos reflejar incertidumbre total sobre transformaciones a dicho parámetro. Sin embargo, la distribución uniforme no es \textit{invariante ante transformaciones}. Por ello, se han buscado distribuciones no informativas diferentes a la uniforme y que sí cumplan con la invarianza ante transformaciones. La más utilizada es la \textit{inicial de Jeffreys}. 

\dfn{\textbf{Inicial de Jeffreys}\\
\label{def:Jeffreys}

La distribución \textit{inicial de Jeffreys} para un parámetro $\theta$ se define en términos de la información de Fisher como: 
\begin{equation*}
p(\theta) \propto \sqrt{I_x(\theta)} \quad \text{donde} \quad I_x(\theta) = -E\left[\dfrac{\partial^2}{\partial\theta^2} ln\left(p(x|\theta)\right) \right] 
\end{equation*}
Un desarrollo de cómo obtener este resultado de invarianza se puede encontrar en \textcite[81-85]{Mendoza11}.\\ 

Ciertamente la inicial de Jeffreys logra superar la primera crítica a las distribuciones iniciales uniformes no informativas. Sin embargo, otra crítica a las distribuciones uniformes también suele estar dirigida a esta distribución de Jeffreys. Para ejemplificarla consideremos el caso en el que tenemos una observación $x$ proveniente de una distribución normal con varianza conocida. En este caso tenemos que la inicial de Jeffreys es la siguiente: 
\begin{align*}
p(\theta = \mu) &\propto \sqrt{I_x(\theta = \mu)} = \sqrt{-E\left[\dfrac{\partial^2}{\partial\mu^2} ln\left(p(x|\mu)\right) \right]}\\ \intertext{donde}
ln\left(p(x|\mu)\right) &= -\dfrac{ln(2\pi\sigma^2)}{2}-\dfrac{(x-\mu)^2}{2\sigma^2}\\ 
&\Rightarrow \dfrac{\partial}{\partial\mu} ln\left(p(x|\mu)\right) = \dfrac{x-\mu}{\sigma^2}\\
&\Rightarrow \dfrac{\partial^2}{\partial\mu^2} ln\left(p(x|\mu)\right) = -\dfrac{1}{\sigma^2}\\
&\Rightarrow I_x(\theta = \mu) = \dfrac{1}{\sigma^2},\\
\intertext{por lo que,}
p(\theta = \mu) &\propto \dfrac{1}{\sigma^2} \propto 1.
\end{align*}
Es decir, la inicial de Jeffreys en este caso coincide con la distribución ``uniforme'' para $\theta = \mu$. La crítica a este tipo de distribuciones radica en que, si integramos sobre todo el espacio parametral--- en este caso $\mathbb{R}$--- vemos que no integra a 1. Esto es, esta distribución es \textit{impropia}. \textcite[27-28]{Robert07} presenta algunas justificaciones para utilizar distribuciones iniciales impropias. La más razonable, desde mi punto de vista, resulta ser que en realidad cualquier inferencia o decisión se deberá tomar--- como ya he mencionado--- con la distribución posterior. Mientras esta distribución posterior sea propia, es posible utilizar distribuciones iniciales impropias. Otra buena justificación es cuando la inicial impropia puede ser vista como un límite de distribuciones propias, pero de esto hablo un poco más adelante.\\ 

Si a alguien no satisfacen estas justificaciones, empero, es posible especificar \textit{distribuciones débilmente informativas} en el sentido de aquellas que, siendo distribuciones propias, buscan reflejar la mayor incertidumbre razonable o posible. Este enfoque es apoyado por \textcite[55,415-416]{Gelman13}, por ejemplo, cuando se tiene una regresión logística en la que para todo propósito práctico los efectos de los coeficientes no se esperan que sean mayores a 10 en la escala logística, por lo que una distribución inicial que concentre su probabilidad en esta región--- sin que esto signifique que no haya probabilidad fuera de la misma--- sería razonable. 

\subsection*{Distribuciones iniciales informativas}

Cuando efectivamente se quiere reflejar la existencia de información inicial, es usual recurrir a una familia paramétrica conocida y, con base en algún criterio o proceso, determinar la distribución inicial. Uno de dichos métodos es cuando se tiene una idea general del valor esperado y la dispersión del parámetro y se utiliza esta información para fijar la distribución inicial como aquella que tiene como media y varianza estos valores. Por ejemplo, si suponemos que la distribución inicial de un parámetro es una distribución normal, basta con especificar $\mu$--- el parámetro del valor esperado--- y $\sigma^2$--- o alguna transformación de este como parámetro de dispersión---. Una alternativa más robusta--- sobre todo en espacios no restringidos-- es utilizar ciertos percentiles en lugar de momentos para fijar la distribución, pero la idea sigue siendo la misma: una vez elegida una familia paramétrica, basta determinar sus parámetros con base en información inicial resumida mediante alguna cantidad.\\

Hay ocasiones en las que en lugar de pensar directamente en los parámetros $\theta$ podemos pensar en términos del resultado $x$ de nuestro experimento--- o una observación futura $\tilde{x}$--- como frecuentemente podría suceder con un modelo de regresión. En estos casos podemos utilizar la distribución predictiva inicial para determinar la distribución que buscamos, recordando que: 
\begin{equation*}
p(\tilde{x}) = \int\limits_\Omega p(\tilde{x}|\theta)p(\theta)d\theta,
\end{equation*} 
por lo que podríamos utilizar un enfoque de momentos o cuantiles como el mencionado en el párrafo anterior. Empero, gracias a la simulación por computadora, es relativamente sencillo visualizar mediante histogramas, densidades o resúmenes las implicaciones en la distribución de $x$ o $\tilde{x}$ que podrían tener diferentes distribuciones iniciales $p(\theta)$. Se puede, por ejemplo, tener una idea del valor esperado, dispersión o cuantiles de $x$ y mediante prueba y error seleccionar parámetros de $p(\theta)$ consistentes con dicha información previa.\\

Sobre todo antes de los avances computacionales, uno de los objetivos en un análisis bayesiano era simplificar al máximo el proceso de cálculo de la distribución posterior. Una forma de hacerlo es elegir una distribución inicial con una forma funcional que se conserve al ser multiplicada por la verosimilitud en el teorema de Bayes. Esto da lugar a lo que se conoce como \textit{distribuciones iniciales conjugadas}: 

\dfn{\textbf{Distribución conjugada}\\
\label{def:Conjugada}

Sea $x$ una variable aleatoria con distribución $p(x|\theta)$, entonces la familia de distribuciones iniciales $\mathcal{F}=\left\lbrace p(\theta) \right\rbrace$ es \textit{conjugada} para $p(x|\theta)$ si $p(\theta|x)\,\in\,\mathcal{F}$.\\

Dejando de lado casos triviales como cuando se considera $\mathcal{F}$ la familia de todas las distribuciones, la noción de distribuciones condicionales es útil cuando se hace uso de alguna forma partamétrica particular. Por ejemplo, supongamos que tenemos un experimento en el que consideramos que $x$, dado $\theta$, se distribuye binomial. En esta situaciones tenemos que la función de verosimilitud, que es una función de $\theta$, tiene la siguiente forma: 
\begin{equation*}
p(x|\theta) \propto \theta^x(1-\theta)^{n-x}.
\end{equation*}
Si queremos que al multiplicar esta expresión por una distribución inicial $p(\theta)$ el resultado $p(\theta|x)$ siga perteneciendo a la misma familia de $p(\theta)$, lo que necesitamos es elegir la distribución inicial que tenga la misma forma--- como función de $\theta$--- que $p(x|\theta)$. En el caso de la verosimilitud binomial, resulta que una distribución inicial beta es conjugada. En efecto, su forma es la misma de la binomial:
\begin{align*}
\theta &\sim \mathcal{B}eta(\alpha,\beta) \; \Rightarrow\; p(\theta) \propto \theta^{\alpha-1}(1-\theta)^{\beta-1} \quad \text{y}\\
x|\theta &\sim Binom(n,\theta) \; \Rightarrow\; p(x|\theta) \propto \theta^{x}(1-\theta)^{n-x},\\
\intertext{por lo que, al utilizar el teorema de Bayes tenemos que,}
p(\theta|x) &\propto \theta^{\alpha-1}(1-\theta)^{\beta-1}\theta^{x}(1-\theta)^{n-x}\\ 
&\propto \theta^{(\alpha+x)-1}(1-\theta)^{(\beta+n-x)-1}\\
\Rightarrow \theta |x &\sim \mathcal{B}eta(\alpha+x, \beta+n-x)
\end{align*}
La gran ventaja de las distribuciones conjugadas es que, al mantener la familia paramétrica, la actualización bayesiana se reduce a actualizar los parámetros de la distribución inicial. Más aún, es frecuente la interpretación de los parámetros iniciales como equivalentes a una \textit{muestra previa}. Por ejemplo, en el caso binomial, $x$ se interpreta como el número de éxitos, mientras que $n-x$ representa el número de fracasos en el experimento. Haciendo el paralelismo con los hiperparámetros de la distribución inicial, $(\alpha-1)$ y $(\beta-1)$ pueden interpretarse, respectivamente, como éxitos y fracasos previos. De esta manera, la distribución posterior \textit{suma} los éxitos previos con los del experimento--- $\alpha -1 + x$--- y los fracasos previos con los del experimento--- $\beta -1 + (n-x)$---. Empero, al utilizar esta interpretación para especificar distribuciones iniciales informativas se debe cuidar que efectivamente la hipotética muestra previa refleje de manera aceptable la incertidumbre inicial. Puede no ser tan simple determinar realmente cuánta información conlleva una muestra previa de un determinado tamaño, por lo que se pudiera correr el riesgo de subestimar la influencia que tendrá una distribución inicial determinada de esta manera sobre la distribución posterior.\\ 

En ocasiones, por el contrario, esta interpretación de muestras previas puede utilizarse también para buscar una distribución no informativa. Podemos, por ejemplo, especificar como inicial aquella distribución cuyos parámetros representen una muestra previa de tamaño cero, lo que se conoce como distribuciones iniciales mínimo informativas límites de conjugadas. En el caso de la distribución beta, una muestra previa de tamaño cero induce que ambos parámetros sean iguales a 1, por lo que la distribución límite de conjugadas resulta ser una $\mathcal{B}eta(\alpha = 1, \beta = 1)$ que resulta ser equivalente a una distribución uniforme sobre el intervalo $[0,1]$. Sin embargo, como discutía al presentar las distribuciones no informativas, es frecuente que estos límites de distribuciones sean distribuciones impropias, como sucede en el caso normal.\footnote{Para ver el desarrollo de la distribución mínimo informativa límite de conjugadas normal puede consultarse \textcite[79-80]{Mendoza11} o {\color{Red} o más adelante en la sección de modelo lineal.}} A pesar de ello, cuando llevan a una distribución posterior propia, estas son frecuentemente utilizadas.\\

Independientemente de cuál sea la distribución inicial que se proponga en un análisis--- o incluso si se proponen varias con el fin de realizar un análisis de sensibilidad ante diferentes supuestos iniciales--- es importante recordar que una de las ventajas de este paradigma bayesiano es que permite transparentar o enfatizar las decisiones subjetivas del estadístico y, por consiguiente, poner en contexto el alcance de sus conclusiones. Ciertamente esta subjetividad es uno de los postulados más comentados por quienes no comparten el paradigma bayesiano. Sin embargo, como bien nos recuerda \textcite[110]{Berger85} al citar a Box y a Good, cualquier supuesto en un modelo puede considerarse como subjetivo y, siempre que existan justificaciones o consideraciones sobre los supuestos iniciales que tenga un análisis, es mejor ser explícito en ellos que correr el riesgo de ignorarlos ``debajo del tapete'' de la objetividad. 