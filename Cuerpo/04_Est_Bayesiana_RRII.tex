\chapter{La probabilidad no existe}
	
Cuando nos enfrentamos a situaciones inciertas, constantemente medimos nuestra incertidumbre de manera personal, con base en la información que tenemos disponible. Esta medición la expresamos coloquialmente mediante el término \textit{probabilidad}. Por ejemplo, nos podemos preguntar la probabilidad de que en una elección popular, una candidatura haya recibido entre el 30\% y el 35\% de los votos. Más aún, como dice \textcite{Berger85}, es común ``pensar en términos de probabilidades personales todo el tiempo: cuando se apuesta al resultado de un partido de fútbol americano, cuando se evalúa la posibilidad de lluvia al día siguiente...''.\\ 

Es decir, día con día utilizamos el término probabilidad para referirnos a apreciaciones subjetivas de la plausibilidad de cosas inciertas. A esta conceptualización de la probabilidad como una medida personal de la incertidumbre se le conoce como el paradigma subjetivo o \textit{bayesiano}. Esta es una interpretación filosófica radicalmente distinta a las más tradicionales: la empírica o \textit{frecuentista} y la \textit{clásica} \parencite{Nozer17,GP16}. 
	
\section{¿Probabilidad o probabilidades?}

Desde esta óptica, la probabilidad en sentido matemático no sería, pues, un concepto ajeno ni incompatible al cotidiano; por el contrario, siendo en el fondo el mismo, permitiría extender su uso a todas aquellas situaciones en las que no aplican las otras perspectivas \parencite{Berger85,GP16}. ¿Cuáles serían algunos ejemplos de dichas situaciones?\\
	
El paradigma clásico está basado en ``\textit{simetrías} o en propiedades físicas''\parencite{GP16}. En virtud de dichas simetrías las probabilidades asignadas a los eventos son iguales. Por ello, puede aplicarse a situaciones proclives al consenso, generalmente juegos de azar, y donde la regla general de probabilidades es: casos favorables entre casos totales. En lo que respecta a las probabilidades personales, estas pueden o no coincidir, incluso en las situaciones más proclives a un consenso.\\ 
	
Por ejemplo, un lanzamiento de una moneda tiene dos posibles resultados igualmente probables... o no. Reducir la probabilidad a que \textit{siempre} deba ser 0.5 es un error \parencite{Nozer17}. Si alguien tiene pruebas de que una moneda particular está cargada, pudiera asignar una probabilidad radicalmente distinta al águila que al sol, mientras que quien desconoce esta información medirá la incertidumbre que rodea al lanzamiento con una asignación equiprobable. Ambas mediciones son válidas, solamente difieren en que son realizadas por sujetos con distinto grado de incertidumbre o conocimiento sobre el fenómeno de interés. Lo que sí podemos decir es que esta interpretación clásica es la más restrictiva pues se reduce al hecho de que la probabilidad de algún evento siempre es equitativa y los casos en los que eso sea una buena aproximación a la realidad son relativamente pocos.\\	 
	 
Por otro lado, para el paradigma frecuentista, la probabilidad es un límite de frecuencias relativas de eventos repetidos bajo condiciones similares. Podríamos pensar en una extensión del concepto clásico: casos favorables entre casos totales, cuando los casos totales tienden a infinito. Así, ``únicamente los sucesos que pueden ser repetidos tienen probabilidad''\parencite{Aquino10}. Es decir, la probabilidad sería una propiedad de un colectivo  y no de eventos individuales \parencite{Nozer17}.\\ 

¿Cuál sería pues la probabilidad de que cierto partido político gane las próximas elecciones presidenciales en México o de que la Selección Nacional logre jugar un quinto partido en el siguiente Mundial de futbol? Dichos eventos son únicos, no pueden repetirse infinitamente bajo las mismas circunstancias con tal de que seamos capaces de registrar empíricamente su límite de frecuencias relativas. Claro, podemos pensar en que hayan \textit{suficientes} eventos bajo condiciones \textit{similares} como para que la probabilidad sea aproximadamente, digamos, 30\%. Pero, ¿cuántos eventos son suficientes? y ¿qué tan similares deben ser? \parencite{Nozer17}. Por el contrario, para la perspectiva bayesiana sí que podemos expresar, cada uno de nosotros, nuestras probabilidades subjetivas sobre ellos.\\ 
	
	De manera general se podría decir que los paradigmas tradicionales interpretan la probabilidad exclusivamente como una medida de variabilidad. Dicha variabilidad es un concepto necesario, ciertamente, pero más limitado que aquel de incertidumbre: la incertidumbre puede derivarse de la variabilidad, pero existen muchos fenómenos que son inciertos aunque no presenten variabilidad. Pensemos en el ejemplo al que me refería al inicio de este capítulo. La proporción de votos de una candidatura en una elección es una proporción fija y que no varía una vez concluida la votación. Sin embargo, nos podemos hacer preguntas probabilísticas acerca de ella porque es desconocida, al menos mientras no se anuncian los resultados oficiales.\\ 
	
	Es posible, incluso, llevar el argumento al extremo: ¿cuál es la probabilidad de que mis dos hermanos cumplan años el mismo día? Este es un evento cierto o falso, totalmente determinado en el pasado pues, o bien nacieron el mismo día del año o no. Por lo mismo, sería difícil hacer una ``estimación probabilística'' de ello desde el punto de vista lógico o frecuentista. Alguien podría argumentar que, asumiendo equiprobabilidad e ignorando los años bisiestos, esta debería ser de una en 365. Alguien más, en un espíritu más frecuentista, podría decir que ésta debe ser la probabilidad de que sean gemelos y, por lo mismo, igual a la proporción de nacimientos gemelares. Si me preguntan a mí, les diría que esa probabilidad es 1: sé que ambos nacieron el 16 de diciembre.\\	
	
	El estadístico y actuario italoaustríaco Bruno de Finetti, acuñó la frase que le da nombre a este capítulo y que sintetiza esta visión bayesiana de la probabilidad. Para los bayesianos, LA probabilidad única, absoluta y objetiva no existe; más bien es una medida subjetiva de la incertidumbre que un individuo particular tiene frente al fenómeno de interés.\\ 
	
	
	Esta argumentación filosófica se ve reforzada por una justificación matemática formal: una teoría de decisión. Con base en unos axiomas, llamados de coherencia, se puede demostrar que un decisor, ante un problema de decisión con incertidumbre, debe actuar de la siguiente manera:

\begin{enumerate}
\item Expresar su incertidumbre sobre los eventos inciertos relevantes en una medida llamada probabilidad subjetiva.
\item Reflejar sus preferencias sobre las posibles consecuencias mediante otra medida llamada utilidad o, equivalentemente, a través de una pérdida. 
\item Tomar la decisión que maximice la utilidad esperada o, equivalentemente, minimice la pérdida esperada. 
\end{enumerate}   
	
Esta teoría de decisión tiene el sentido normativo de que esta es la manera óptima de actuar \textit{si se quiere evitar violar los axiomas de coherencia} y de ninguna manera en un sentido descriptivo que diga que los seres humanos actuamos de esa forma o incluso, que se tengan que aceptar los propios axiomas. Dicha justificación axiomática escapa los objetivos de esta tesis, pero una primera introducción a ella puede consultarse en referencias como \textcite{Mendoza11} o \textcite{Bernardo81}. No obstante, debe enfatizarse que son esos axiomas los que dan sustento teórico al uso de probabilidades subjetivas y que de ellos se deriva el paradigma inferencial bayesiano que procedo a discutir.\\

Notemos que el procedimiento derivado de los axiomas está encaminado, de cierta forma, a reducir el riesgo de las consecuencias que puedan surgir en un problema de decisión. Cualquier decisor que \textit{usa} la teoría de decisión hará esto. Sin embargo, desde mi punto de vista, la diferencia entre ello y lo que hace un \textit{estadístico} bayesiano estriba en que este último se preocupa también por minimizar la incertidumbre asociada al fenómeno de su interés, recabando mayor información en la forma de datos datos.\\ 

Algunos colegas pueden bromear, a manera de crítica, sobre el bayesiano que no necesita datos para estimar lo que sea, pues bastarían sus probabilidades y pérdidas subjetivas. Ciertamente habrá ocasiones donde tengamos que tomar este tipo de decisiones, por ejemplo cuando ya pensamos que contamos con la única información disponible. Más aún, la justificación axiomática lo permite. Al margen del buen humor, la realidad es que si \textit{exclusivamente} tomáramos decisiones \textit{a priori} efectivamente correríamos el riesgo de ser obtusos. Desde mi perspectiva, un \textit{estadístico} bayesiano debe preocuparse por los datos y, una vez recabados, proceder al análisis. Así pues, es necesario continuar esta introducción al paradigma bayesiano presentando el mecanismo práctico por el cual un estadístico bayesiano aprende de los datos y \textit{actualiza} sus creencias subjetivas.
	
\section{Aprendizaje bayesiano}

Un punto clave de la teoría de decisión es que la definición matemática de la probabilidad subjetiva satisface los axiomas de Kolmogorov que dan sustento a la teoría usual de probabilidades. Es decir, las probabilidades subjetivas satisfacen los mismos teoremas y resultados que se aprenden en los cursos de probabilidad. Uno de los más elementales es el teorema que hace posible el \textit{aprendizaje} de los datos: el Teorema de Bayes.

\begin{teo} \label{teo:Bayes_1}
\textbf{Teorema de Bayes. (Notación probabilística)}\\
Sean $A$ y $B$ eventos tales que $\Pr(B) \neq 0$. Se cumple que: 
\begin{equation*}
\Pr(A|B)=\dfrac{\Pr(B|A)\Pr(A)}{\Pr(B)}\;,
\end{equation*}
donde $\Pr(A|B)$ y $\Pr(B|A)$ son probabilidades condicionales, mientras que $\Pr(A)$ y $\Pr(B)$ son las respectivas probabilidades marginales. 
\end{teo}

Vale la pena detenerse a pensar qué implica este teorema en nuestro contexto; no por nada el apelativo del paradigma hace honor a Thomas Bayes, mismo personaje al que se refiere el teorema. A partir de este momento utilizaré el término \textit{distribución} de manera general para referirme, por ejemplo, a una ley de probabilidad o a sus funciones de densidad o masa de probabilidad, según sea el caso.\\ 

Cuando hacemos inferencia estadística paramétrica, usualmente estamos interesados en conocer sobre una cantidad desconocida $\theta$, llamada parámetro. Bajo el paradigma bayesiano, este es desconocido y, por tanto, le asignamos una  distribución de probabilidad \textit{inicial} o \textit{a priori} $f(\theta)$ que resume nuestro estado de conocimiento inicial sobre el parámetro. Posteriormente, para reducir nuestra incertidumbre procedemos a recabar información en forma de datos $x$, a los que asignamos una distribución condicional dado el parámetro--- $f(x|\theta)$--- y que, como función del parámetro, es llamada función de verosimilitud--- $L(\theta)$---.\\ 

Aprender de los datos significaría, entonces, \textit{invertir} las probabilidades y conocer la distribución del parámetro dados los datos $f(\theta|x)$. Precisamente una de las primeras motivaciones de la estadística bayesiana era justamente la de encontrar una forma de calcular estas \textit{probabilidades inversas} \citep{Robert07}: 
\begin{quote}
... el propósito de un análisis estadístico es fundamentalmente un propósito de \textit{inversión}, puesto que busca recuperar las causas--- reducidas a los parámetros del mecanismo probabilístico de generación--- de los efectos--- resumidos por las observaciones. En otras palabras, al observar un fenómeno aleatorio dirigido por un parámetro $\theta$, los métodos estadísticos permiten deducir de estas observaciones una \textit{inferencia} (esto es, un resumen, una caracterización) sobre $\theta$ [...] La inferencia está basada entonces en la distribución de $\theta$ condicional en $x$ [...] llamada la \textit{distribución posterior}...
\end{quote} 

Esto lo hacemos mediante el teorema de Bayes: 

\begin{teo} \label{teo:Bayes_2}
\textbf{Teorema de Bayes. (Notación estadística)}\\
Sean $\theta$ un vector de parámetros desconocidos, $f(\theta)$ su distribución inicial y $x$ información adicional en forma de datos conocidos. Entonces, la distribución posterior de $\theta$, una vez observados los datos, es: 
\begin{equation*}
f(\theta|x)=\dfrac{f(x|\theta)f(\theta)}{f(x)}\;,
\end{equation*}
donde $f(x|\theta) = L(\theta)$ es la función de verosimilitud para el vector de parámetros $\theta$, considerando los datos $x$ como fijos, y con $f(x)$ la distribución marginal de los datos. 
\end{teo}

Visto todo como función de $\theta$, nuestra cantidad de interés, la expresión anterior se reduce a:  
\begin{equation} \label{eq:Bayes_Prop}
f(\theta|x) \propto L(\theta)f(\theta)\;,
\end{equation}
pues $f(x)$ depende solo de los datos ya observados y funge como la constante normalizadora que hace que la posterior integre a 1. Esta última representación resume el proceso de aprendizaje bayesiano: \textit{la posterior es proporcional a la verosimilitud por la inicial}.\\ 

Otra forma de resumir el proceso de aprendizaje bayesiano es mediante lo que \textcite{GP16} llama, a manera de recurso nemotécnico, la \textit{única receta de la inferencia bayesiana}\label{receta_bayesiana}:
\begin{quote}
... encontrar la distribución condicional de todas aquellas cantidades de interés cuyo valor desconocemos dado el valor conocido de las variables observadas.
\end{quote}
Puesto de otra forma por el mismo autor: la distribución final sería la inferencia. Esto resume el lugar central que ocupa la distribución posterior en el paradigma bayesiano. No obstante, como bien advierte el autor, así como \textcite{Berger85}, es deseable resumir esta inferencia general en un proceso específico, como se puede intuir también de la cita anterior de Christian P. \textcite{Robert07}. 

\section{Distribuciones iniciales}

Existe entonces un mecanismo práctico que permite aprender de los datos, invirtiendo probabilidades, para calcular \textit{distribuciones posteriores}. Sin embargo, para lograr esto es necesario empezar con una \textit{distribución inicial} que refleje la incertidumbre que se tenga frente a un fenómeno de interés. Existen muchas formas diferentes de determinar la distribución inicial, en esta sección presentaré algunas de ellas con base en \textcites{Berger85,Congdon06,Robert07,Gelman13}.\\ 

Empecemos por considerar el caso cuando el espacio parametral sobre el que tenemos que determinar las probabilidades es discreto. Por ejemplo, pensemos en fijar una distribución inicial para un partido de futbol, en el que hay 3 posibles resultados: victoria para el local, victoria para el visitante o empate. La primera distribución posible está basada en lo que se conoce como el \textit{criterio de la razón insuficiente}. Fue propuesto por Laplace y está relacionado a la interpretación clásica de la probabilidad puesto que establece que, a falta de información adicional que permita invalidarlo, se debería tomar el supuesto de que todos los eventos son igualmente probables. Así pues, podríamos asignar una distribución discreta uniforme de $1/3$ a cada uno de los 3 resultados del partido.\\

Sin embargo, podría haber razones suficientes para que esta no sea la distribución inicial. Por ejemplo, podemos creer que el equipo local es mejor que el equipo visitante y, en consecuencia, asignar una probabilidad del  60\% a que el local gane, 30\% al empate y 10\% a una sorpresiva victoria de la visita. Es posible que otro aficionado, piense que un 30\% de probabilidad de empate es demasiado alto, en cuyo caso sería necesario ajustar las probabilidades así calculadas hasta encontrar una combinación aceptable. Pudiéramos también asignar una distribución inicial basados en algún tipo de frecuencia relativa histórica.\\ 

Otra forma de asignar probabilidades a eventos es pensar en apuestas que consideremos justas. Imaginemos un mercado como el del sitio web 	\href{https://www.predictit.org/}{Predict It} en el que podemos apostar una cantidad $p \in (0,1)$ de centavos de dólar a que un evento suceda. Si el evento efectivamente sucede, nuestra apuesta vale $1$ dólar y habremos ganado $1-p$ centavos. Si el evento no sucede, perdemos $p$ centavos. Como la cantidad apostada es pequeña, podríamos considerar una función de utilidad lineal del dinero. Por otro lado, pensemos en una apuesta justa, es decir, una cuya utilidad esperada fuera $0$.\\ 

La utilidad esperada $\E{g}$ es igual a la utilidad cuando el evento sucede, por la probabilidad de que suceda, más la utilidad--- en este caso, pérdida--- cuando el evento no sucede, por la probabilidad de que no suceda. Si denotamos al evento como $A$ y a su probabilidad como $\Pr(A)$, tenemos que : 
\begin{align*}
\E{g} = 0 &\Leftrightarrow (1-p)\Pr(A) - p\Pr(A^c) = 0 \\
&\Leftrightarrow (1-p)\Pr(A) - p(1-\Pr(A))= 0\\ 
&\Leftrightarrow \Pr(A) = p.
\end{align*}
Si apostáramos una cantidad mayor estaríamos arriesgándonos de más, o dicho de otra forma, tendríamos una utilidad esperada negativa, por lo que no nos convendría la apuesta. Querríamos apostar menos, pues en ese caso nuestra utilidad esperada sería positiva. Esto quiere decir que podemos pensar en las probabilidades subjetivas de un evento como la máxima cantidad que estaríamos dispuestos a considerar en una apuesta de este tipo. Este tipo de apuestas imaginarias podrían constituir un mecanismo para dilucidar probabilidades subjetivas.\\ 

Ahora bien, ¿qué pasa cuando la distribución inicial debe ser continua? A continuación presento algunos métodos para elegir este tipo de distribuciones.

\subsection{Distribuciones no informativas}

Al igual que con las distribuciones discretas podemos comenzar por el criterio de la razón insuficiente y proponer una distribución que busque reflejar una ignorancia general en la que no se prefieran \textit{a priori} algunos resultados o valores de los parámetros. Así surgen las llamadas \textit{distribuciones iniciales no informativas}. Estas se pueden usar cuando alguien cree que no cuenta con información inicial y se encuentra en una situación de ignorancia total. Alternativamente, se podría ignorar la información existente porque se busca presentar una distribución relativamente más ``objetiva'', ya sea porque el contexto así lo exige, porque se busca llevar acabo un análisis de sensibilidad bajo diferentes supuestos o por algún otro motivo.\\ 

El criterio de la razón insuficiente buscaría proponer una asignación equiprobable a los eventos. Así pues, la primera distribución inicial no informativa que se puede considerar es la uniforme. Esto es que la distribución sea proporcional a una constante:
\begin{equation*}
f(\theta) \propto c
\end{equation*}
Esta distribución, sin embargo, ha sufrido algunas críticas. La primera de ellas es que, si uno quiere reflejar incertidumbre total sobre un parámetro, esto querría decir que también deberíamos reflejar incertidumbre total sobre transformaciones a dicho parámetro. Sin embargo, la distribución uniforme no es \textit{invariante ante transformaciones}. Por ello, se han buscado distribuciones no informativas diferentes a la uniforme. La más utilizada es la \textit{regla de Jeffreys}.\\ 

Como dice \textcite{Regueiro12}, la regla de Jeffreys es un criterio que ``extiende la propuesta de Laplace al considerar que una distribución \textit{Uniforme} es una descripción razonable para un caso de poca información'' pero sobre una \textit{reparametrización particular} del parámetro de interés que pueda interpretarse como la media de una normal. De dicho criterio se desprende entonces una forma general de distribución no informativa conocida como la inicial de Jeffreys, cuyo desarrollo puede consultarse en \textcite{Mendoza11}.

\dfn{\textbf{Inicial de Jeffreys}\\
\label{def:Jeffreys}

La distribución \textit{inicial de Jeffreys} para un parámetro $\theta$ se define en términos de la información de Fisher como: 
\begin{equation*}
f(\theta) \propto \sqrt{I_x(\theta)} \quad \text{donde} \quad I_x(\theta) = -\E{\dfrac{\partial^2}{\partial\theta^2} ln\left(f(x|\theta)\right)} 
\end{equation*}
 
Ahora bien, la inicial de Jeffreys logra superar la primera crítica a las distribuciones iniciales uniformes no informativas, pero no otro tipo de críticas. Consideremos el caso en el que tenemos una observación $x$ proveniente de una distribución normal con varianza conocida. En este caso tenemos que la inicial de Jeffreys es la siguiente: 
\begin{align*}
f(\theta = \mu) &\propto \sqrt{I_x(\theta = \mu)} = \sqrt{-\E{\dfrac{\partial^2}{\partial\mu^2} ln\left(f(x|\mu)\right)}} 
\intertext{donde}
ln\left(f(x|\mu)\right) &= -\dfrac{ln(2\pi\sigma^2)}{2}-\dfrac{(x-\mu)^2}{2\sigma^2}\\ 
&\Rightarrow \quad \dfrac{\partial}{\partial\mu} ln\left(f(x|\mu)\right) = \dfrac{x-\mu}{\sigma^2}\\
&\Rightarrow \quad \dfrac{\partial^2}{\partial\mu^2} ln\left(f(x|\mu)\right) = -\dfrac{1}{\sigma^2}\\
&\Rightarrow \quad I_x(\theta = \mu) = \dfrac{1}{\sigma^2},
\intertext{por lo que,}
f(\theta = \mu) &\propto \dfrac{1}{\sigma^2} \propto 1.
\end{align*}
Es decir, la inicial de Jeffreys en este caso coincide con la distribución ``uniforme'' para $\theta = \mu$. El problema radica en que, si integramos sobre todo el espacio parametral $\mathbb{R}$, el resultado no es 1 como requiere una distribución de probabilidad; esta distribución es \textit{impropia}.\\ 

\textcite{Robert07} presenta algunas justificaciones para utilizar distribuciones iniciales impropias. La más razonable, desde mi punto de vista, resulta ser que en realidad cualquier inferencia o decisión se tenderá a tomar--- como ya he mencionado--- con la distribución posterior. Mientras esta distribución posterior sea propia, sería posible utilizar distribuciones iniciales impropias. Otra justificación es cuando la inicial impropia puede ser vista como un límite de distribuciones propias, pero de esto hablo un poco más adelante.\\

Como puede intuirse del hecho de que existen al menos dos criterios distintos, no hay, pues, una única forma de distribución no informativa y en cada contexto se deberá determinar lo que constituye dicha ausencia de información inicial.

\subsection{Distribuciones informativas}

Cuando efectivamente se quiere reflejar la existencia de información inicial, es usual recurrir a una familia paramétrica conocida y, con base en algún criterio o proceso, determinar la distribución inicial. Uno de dichos métodos es cuando se tiene una idea general del valor esperado o rango de valores plausibles del parámetro y se utiliza esta información para fijar la distribución inicial como aquella que cuya media y varianza es compatible dichos valores.\\ 

Por ejemplo, si suponemos que la distribución inicial de un parámetro es una distribución normal, basta con especificar $\mu$--- el parámetro del valor esperado--- y $\sigma^2$--- o alguna transformación de este como parámetro de dispersión---. De acuerdo con \textcite{Berger85}, una mejor alternativa--- sobre todo en espacios no restringidos-- es utilizar ciertos percentiles en lugar de momentos para fijar la distribución, pero la idea sigue siendo la misma: una vez elegida una familia paramétrica, basta determinar sus parámetros con base en información inicial resumida mediante alguna cantidad.\\

Hay ocasiones en las que en lugar de pensar directamente en los parámetros $\theta$ podemos pensar en términos del resultado $x$ de nuestro experimento--- o una observación futura $\tilde{x}$--- como frecuentemente podría suceder con un modelo de regresión. De manera particular, podríamos utilizar la información inicial que tengamos para predecir alguna observación futura.\\ 

Si conociéramos el valor del parámetro $\theta$, resultaría natural intentar predecir el resultado de una observación futura $\tilde{x}$ mediante la distribución condicional $f(\tilde{x}|\theta)$. Sin embargo, en el contexto de incertidumbre sobre los parámetros en el que estamos trabajando, aunque tenemos cierta información, en realidad el valor específico de $\theta$ es desconocido. Por eso, debemos considerar más bien la distribución conjunta de las dos cantidades desconocidas, $\tilde{x}$ y $\theta$. A partir de esta distribución $f(\tilde{x},\theta)$ podemos obtener la distribución marginal de la observación futura y con ella predecir: 
\begin{equation*} 
f(\tilde{x})=\int\limits_\Theta f(\tilde{x},\theta)d\theta=\int\limits_\Theta f(\tilde{x}|\theta)f(\theta)d\theta.
\end{equation*}
Esta distribución marginal es conocida como \textit{distribución predictiva inicial}. Al calcularla estamos promediando las distribuciones condicionales a través de los diferentes valores que el parámetro $\theta$ puede tomar.\\

Hoy en día, es relativamente sencillo visualizar mediante histogramas, densidades o resúmenes las implicaciones en la distribución de $x$ o $\tilde{x}$ que podrían tener diferentes distribuciones iniciales $f(\theta)$. Por eso podríamos utilizar un enfoque de momentos o cuantiles para elegir la distribución inicial $f(\theta)$ que produzca las mejores predicciones para $\tilde{x}$. Es decir, se puede, por ejemplo, tener una idea previa del valor esperado, dispersión o cuantiles de $x$ y mediante prueba y error seleccionar parámetros de $f(\theta)$ consistentes con dicha información previa.\\

También es posible especificar \textit{distribuciones débilmente informativas} basados en la idea que, aunque haya poca información, se tienen nociones generales de valores que resultarían muy poco razonables. Estas buscan ser un justo medio entre las distribuciones completamente informativas y aquellas no informativas. Este enfoque es particularmente útil en modelos de regresión cuando se pueden tener nociones de los tamaños de los efectos de ciertas variables \parencite{Gelman13}.\\ 

Por ejemplo, \textcite{Regueiro12} busca definir distribuciones iniciales en un modelo predictivo del número de goles anotados en partidos de futbol. Él argumenta que la inicial debe concentrar la mayor parte de la probabilidad en valores que lleven a un número de goles entre $0$ y $20$, sin que esto signifique que no haya probabilidad de más de $20$ goles. En efecto, la mayor cantidad de goles anotados por un equipo en un partido oficial de FIFA es de $31$, pero ya $20$ goles es una cantidad extrema. Ciertamente ``una información inicial que permita que el número esperado de goles se encuentre en el orden de los millones es inapropiada''. 

\subsection{Distribuciones Conjugadas}

Sobre todo antes de los avances computacionales, uno de los objetivos en un análisis bayesiano era simplificar al máximo el proceso de cálculo de la distribución posterior. Una forma de hacerlo es elegir una distribución inicial con una forma funcional que se conserve al ser multiplicada por la verosimilitud en el teorema de Bayes. Esto da lugar a lo que se conoce como \textit{distribuciones iniciales conjugadas}: 

\dfn{\textbf{Distribución conjugada}\\
\label{def:Conjugada}
Sea $x$ una variable aleatoria con distribución $f(x|\theta)$, entonces la familia de distribuciones iniciales $\mathcal{F}=\left\lbrace f(\theta) \right\rbrace$ es \textit{conjugada} para $f(x|\theta)$ si $f(\theta|x)\,\in\,\mathcal{F}$.\\

Dejando de lado casos triviales como cuando se considera $\mathcal{F}$ la familia de todas las distribuciones, la noción de distribuciones condicionales es útil cuando se hace uso de alguna forma partamétrica particular. Por ejemplo, supongamos que tenemos un experimento en el que consideramos que $x$, dado $\theta$, se distribuye binomial. En esta situaciones tenemos que la función de verosimilitud, que es una función de $\theta$, tiene la siguiente forma: 
\begin{equation*}
f(x|\theta) \propto \theta^x(1-\theta)^{n-x}.
\end{equation*}
Si queremos que al multiplicar esta expresión por una distribución inicial $f(\theta)$ el resultado $f(\theta|x)$ siga perteneciendo a la misma familia de $f(\theta)$, lo que necesitamos es elegir la distribución inicial que tenga la misma forma--- como función de $\theta$--- que $f(x|\theta)$. En el caso de la verosimilitud binomial, resulta que una posibilidad es la distribución inicial beta. En efecto, su forma es la misma de la binomial:
\begin{align*}
\theta &\sim \mathcal{B}eta(\alpha,\beta) \; \Rightarrow\; f(\theta) \propto \theta^{\alpha-1}(1-\theta)^{\beta-1} \quad \text{y}\\
x|\theta &\sim Binom(n,\theta) \; \Rightarrow\; f(x|\theta) \propto \theta^{x}(1-\theta)^{n-x},
\intertext{por lo que, al utilizar el teorema de Bayes tenemos que,}
f(\theta|x) &\propto \theta^{\alpha-1}(1-\theta)^{\beta-1}\theta^{x}(1-\theta)^{n-x}\\ 
&\propto \theta^{(\alpha+x)-1}(1-\theta)^{(\beta+n-x)-1}\\
\Rightarrow \theta |x &\sim \mathcal{B}eta(\alpha+x, \beta+n-x)
\end{align*}
La gran ventaja de las distribuciones conjugadas es que, al mantener la familia paramétrica, la actualización bayesiana se reduce a actualizar los parámetros de la distribución inicial.\\ 

Otra justificación frecuente para utilizar distribuciones conjugadas es la interpretación de los parámetros iniciales como equivalentes a una \textit{muestra previa}. Por ejemplo, en el caso binomial, $x$ se interpreta como el número de éxitos, mientras que $n-x$ representa el número de fracasos en el experimento. Haciendo el paralelismo con los hiperparámetros de la distribución inicial, $(\alpha-1)$ y $(\beta-1)$ pueden interpretarse, respectivamente, como éxitos y fracasos previos. De esta manera, la distribución posterior \textit{suma} los éxitos previos con los del experimento, $\alpha -1 + x$, y los fracasos previos con los del experimento, $\beta -1 + (n-x)$.\\ 

Al utilizar esta interpretación para especificar distribuciones iniciales informativas se debe cuidar que efectivamente la hipotética muestra previa refleje de manera aceptable la incertidumbre inicial. Puede no ser tan simple determinar realmente cuánta información conlleva una hipotética muestra previa de un determinado tamaño, por lo que se pudiera correr el riesgo de subestimar la influencia que tendrá una distribución inicial determinada de esta manera sobre la distribución posterior.\\ 

En ocasiones, por el contrario, esta interpretación de muestras previas puede utilizarse también para buscar una distribución no informativa. Podemos, por ejemplo, especificar como inicial aquella distribución cuyos parámetros representen una muestra previa de tamaño cero, lo que se conoce como distribuciones iniciales mínimo informativas límites de conjugadas. En el caso de la distribución beta, una muestra previa de tamaño cero induce que ambos parámetros sean iguales a 1, por lo que la distribución límite de conjugadas resulta ser una $\mathcal{B}eta(\alpha = 1, \beta = 1)$ que es equivalente a una distribución uniforme sobre el intervalo $[0,1]$. Sin embargo, como discutía al presentar las distribuciones no informativas, es frecuente que estos límites de distribuciones sean distribuciones impropias, como sucede en el caso normal \parencite{Mendoza11}. A pesar de ello, cuando llevan a una distribución posterior propia, estas son frecuentemente utilizadas.\\

Independientemente de cuál sea la distribución inicial que se proponga en un análisis--- o incluso si se proponen varias con el fin de realizar un análisis de sensibilidad ante diferentes supuestos iniciales--- es importante recordar que una de las ventajas del paradigma bayesiano es que permite transparentar o enfatizar las decisiones subjetivas del estadístico y, por consiguiente, poner en contexto el alcance de sus conclusiones.\\ 

Ciertamente esta subjetividad es uno de los postulados más comentados por quienes no comparten el paradigma bayesiano. Sin embargo, como bien nos recuerda \textcite{Berger85} al citar a Box y a Good, cualquier supuesto en un modelo puede considerarse como subjetivo y, siempre que existan justificaciones o consideraciones sobre los supuestos iniciales que tenga un análisis, es mejor ser explícito en ellos que correr el riesgo de ignorarlos ``debajo del tapete'' de la objetividad.\\

Este capítulo representa una introducción general al paradigma estadístico bayesiano. El lector interesado en profundizar un poco más sobre el mismo y, en particular, sobre la teoría detrás del modelo concreto utilizado en la tesis así como algunos de los métodos computacionales que permiten en la práctica la aplicación del teorema de Bayes puede consultar la versión completa de la tesis \parencite{TesisAct}.  